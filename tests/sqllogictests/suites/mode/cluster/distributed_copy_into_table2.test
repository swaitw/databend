statement ok
set enable_distributed_copy_into = 1;

statement ok
set global max_threads = 1;

statement ok
set auto_compaction_imperfect_blocks_threshold = 3;

statement ok
drop table if exists products;

statement ok
drop table if exists table_random;

statement ok
drop stage if exists s3;

statement ok
create stage s3 FILE_FORMAT = (TYPE = CSV);

statement ok
create table products (id int not null, name string not null, description string not null);

statement ok
create table table_random(a int not null,b string not null,c string not null) ENGINE = Random min_string_len = 1;

statement ok
copy into @s3 from (select a,b,c from table_random limit 10);

statement ok
copy into @s3 from (select a,b,c from table_random limit 10);

statement ok
copy into @s3 from (select a,b,c from table_random limit 10);

statement ok
copy into @s3 from (select a,b,c from table_random limit 10);

statement ok
copy into products from @s3 pattern = '.*[.]csv' purge = true;

query I
select count(*) from products;
----
40

# table will be auto compacted after copy into, the volume of data is small, so by default setting, it will be compacted to 1 block.
query I
select block_count from fuse_snapshot('default','products') limit 1;
----
1

statement ok
set enable_distributed_copy_into = 0;

statement ok
set auto_compaction_imperfect_blocks_threshold = 50;
